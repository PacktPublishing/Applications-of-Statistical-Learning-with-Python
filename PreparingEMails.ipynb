{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the E-Mails\n",
    "*Curtis Miller*\n",
    "\n",
    "Before attempting to train a classifier we need to get our e-mails in a form we can work with. In this notebook I show how to load in the information identifying e-mails as spam/not spam (often referred to as \"ham\") and how we will process the text to make it usable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Labels\n",
    "\n",
    "First I load in the necessary packages, functions, and objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import email\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `SPAMTrain.label` is a plain text file that contains the file names and a number identifying the file as a spam/ham message. Below is a preview of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SPAMTrain.label\") as f:\n",
    "    spamfiles = f.read()\n",
    "\n",
    "spamfiles.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert this file into a pandas `DataFrame`; it's more useful in that form. I've written code for doing this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedata = pd.DataFrame([f.split(\" \") for f in spamfiles.split(\"\\n\")[:-1]], columns=[\"ham\", \"file\"])    # 1 for ham\n",
    "filedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning an E-Mail\n",
    "\n",
    "Now we need to consider how to clean an e-mail message. Some of the e-mail messages are pure plain text while others have HTML formatting. `BeautifulSoup` allows us to parse the HTML when it occurs, so we will take every e-mail we encounter, create a `BeautifulSoup` object, then turn the contents into a string without HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"RTRAINING/TRAIN_04315.eml\") as f:\n",
    "    filestr = f.read()\n",
    "    bsobj = BeautifulSoup(filestr, \"lxml\")\n",
    "    print(bsobj.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will take a string containing an e-mail and perform the desired cleaning so that we have, as output, a string useful for later purposes. In cleaning we do the following:\n",
    "\n",
    "* Make all characters lower-case\n",
    "* Make all whitespace a single space\n",
    "* Tokenize the text\n",
    "* Stem words\n",
    "* Remove words we don't want, such as stopwords or words that reveal too much about the message (such as `[SPAM]`, which may be the product of another spam filter)\n",
    "* Keep only characters in the alphabet\n",
    "\n",
    "Notice that URLs will be kept, but they will be split. I'm fine with this; I think this is information a spam detector could use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_clean(email_string):\n",
    "    \"\"\"A function for taking an email contained in a string and returning a clean string representing the email\"\"\"\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    email_string = email_string.lower()\n",
    "    email_string = re.sub(\"\\s+\", \" \", email_string)\n",
    "    \n",
    "    email_words = wordpunct_tokenize(email_string)\n",
    "    goodchars = \"abcdefghijklmnopqrstuvwxyz\"    # No punctuation or numbers; not interesting for my purpose\n",
    "    email_words = [''.join([c for c in w if c in goodchars]) for w in email_words if w not in [\"[spam]\"]]\n",
    "    email_words = [w for w in email_words if w not in nltk.corpus.stopwords.words(\"english\") and w is not '']\n",
    "    \n",
    "    return \" \".join(email_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_clean(bsobj.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be called whenever we want to process a message."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
