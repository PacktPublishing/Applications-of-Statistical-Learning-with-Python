{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Spam\n",
    "*Curtis Miller*\n",
    "\n",
    "Now, having seen how to load and prepare our e-mail collection, we can start training a classifier.\n",
    "\n",
    "## Loading And Splitting E-Mails\n",
    "\n",
    "Our first task is to load in the data. We will split the data into training and test data. The training data will be used to train a classifier while the test data will be used for evaluating how well our classifier performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import email\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import string\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SPAMTrain.label\") as f:\n",
    "    spamfiles = f.read()\n",
    "filedata = pd.DataFrame([f.split(\" \") for f in spamfiles.split(\"\\n\")[:-1]], columns=[\"ham\", \"file\"])    # 1 for ham\n",
    "filedata.ham = filedata.ham.astype('int8')\n",
    "filedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emails, test_emails = train_test_split(filedata)\n",
    "train_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load in our training data, storing it in a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"RTRAINING/\"\n",
    "train_email_str = list()\n",
    "for filename in train_emails.file:\n",
    "    with open(basedir + filename, encoding=\"latin1\") as f:\n",
    "        filestr = f.read()\n",
    "        bsobj = BeautifulSoup(filestr, \"lxml\")\n",
    "        train_email_str.append(bsobj.get_text())\n",
    "\n",
    "train_email_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emails = train_emails.assign(text=pd.Series(train_email_str, index=train_emails.index))\n",
    "train_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Features\n",
    "\n",
    "There are lots of words in our e-mails even after stopwords are removed. Our feature space will be how frequently commonly seen words appear in an e-mail. We will combine all the spam and all the ham e-mails together and choose 1000 most-frequently-seen words for each of those classes, and count how often those words are seen in individual e-mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_clean(email_string):\n",
    "    \"\"\"A function for taking an email contained in a string and returning a clean string representing the email\"\"\"\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    email_string = email_string.lower()\n",
    "    email_string = re.sub(\"\\s+\", \" \", email_string)\n",
    "    \n",
    "    email_words = wordpunct_tokenize(email_string)\n",
    "    goodchars = \"abcdefghijklmnopqrstuvwxyz\"    # No punctuation or numbers; not interesting for my purpose\n",
    "    email_words = [''.join([c for c in w if c in goodchars]) for w in email_words if w not in [\"spam\"]]\n",
    "    email_words = [w for w in email_words if w not in nltk.corpus.stopwords.words(\"english\") and w is not '']\n",
    "    \n",
    "    return \" \".join(email_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantext = pd.Series(train_emails.text.map(email_clean), index=train_emails.index)\n",
    "train_emails = train_emails.assign(cleantext=cleantext)\n",
    "train_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emails[train_emails.ham == 0].cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we combine the e-mails to find common words in both spam and ham e-mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_spam = \" \".join(train_emails.loc[train_emails.ham == 0].cleantext)\n",
    "mass_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_ham = \" \".join(train_emails.loc[train_emails.ham == 1].cleantext)\n",
    "mass_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_freq = nltk.FreqDist([w for w in mass_spam.split(\" \")])\n",
    "M = 1000\n",
    "spam_freq.most_common(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_freq = nltk.FreqDist([w for w in mass_ham.split(\" \")])\n",
    "M = 1000\n",
    "ham_freq.most_common(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can find the words that will be in our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [t[0] for t in ham_freq.most_common(M)] + [t[0] for t in spam_freq.most_common(M)]\n",
    "words = set(words)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in generating the features for the e-mails is to count how often the words of interest appear in e-mails in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = dict()\n",
    "for i, s in train_emails.iterrows():\n",
    "    wordcounts = dict()\n",
    "    for w in words:\n",
    "        wordcounts[w] = s[\"cleantext\"].count(w)\n",
    "    feature_dict[i] = pd.Series(wordcounts)\n",
    "\n",
    "pd.DataFrame(feature_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emails = train_emails.join(pd.DataFrame(feature_dict).T, lsuffix='0')\n",
    "train_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Classifier\n",
    "\n",
    "Now we can train a classifier. In this case we're training a Gaussian naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spampred = GaussianNB()\n",
    "spampred = spampred.fit(train_emails.loc[:, words], train_emails.ham)\n",
    "ham_predicted = spampred.predict(train_emails.loc[:, words])\n",
    "ham_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_emails.ham, ham_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier does very well in the training data. How well does it do on unseen test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Performance\n",
    "\n",
    "The final step is to evaluate our classifier on test data to see how well we can expect it to perform on future, unseen data. The steps below prepare the test data like we did the training data, loading and cleaning the e-mails and counting how often the words of interest appear in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_email_str = list()\n",
    "for filename in test_emails.file:\n",
    "    with open(basedir + filename, encoding=\"latin1\") as f:\n",
    "        filestr = f.read()\n",
    "        bsobj = BeautifulSoup(filestr, \"lxml\")\n",
    "        test_email_str.append(bsobj.get_text())\n",
    "\n",
    "\n",
    "cleantext_test = pd.Series([email_clean(s) for s in test_email_str], index=test_emails.index)\n",
    "test_emails = test_emails.assign(cleantext=cleantext_test)\n",
    "\n",
    "feature_dict_test = dict()\n",
    "for i, s in test_emails.iterrows():\n",
    "    wordcounts = dict()\n",
    "    for w in words:\n",
    "        wordcounts[w] = s[\"cleantext\"].count(w)\n",
    "    feature_dict_test[i] = pd.Series(wordcounts)\n",
    "\n",
    "test_emails = test_emails.join(pd.DataFrame(feature_dict_test).T, lsuffix='0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the classifier performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_predicted_test = spampred.predict(test_emails.loc[:, words])\n",
    "print(classification_report(test_emails.ham, ham_predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did very well, just like on the training data! It seems we don't have much (if any) overfitting or underfitting. We could have a classifier ready to deploy.\n",
    "\n",
    "(Of course, our classifier is only as good as the data it was trained on. Perhaps e-mails seen in different contexts or at a different period in time have different characteristics, including both the spam and ham e-mails. In that case the classifier trained here won't be any good since it was trained on the wrong data.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
