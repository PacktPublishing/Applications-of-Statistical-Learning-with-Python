{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the Pictures\n",
    "*Curtis Miller*\n",
    "\n",
    "In this notebook we see the images in our dataset and create some helper tools for managing the data. First, let's load in the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The faces are stored in a CSV file `fer2013.csv`, loaded in next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The faces themselves are in the `pixels` column of the `DataFrame`, in a string. We want to convert the faces to NumPy 48x48 arrays that can be plotted with matplotlib. The values themselves are the intensities of grayscale pixels. We split the strings on spaces and convert characters to their corresponding numbers, reshaping to a desired array.\n",
    "\n",
    "This is all done with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_image(pixelstring):\n",
    "    return np.array(pixelstring.split(' '), dtype=np.int16).reshape(48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(string_to_image(faces.pixels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(string_to_image(faces.pixels[8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As humans we would like to know what the codes in the `emotion` column represent. The following dictionary defines the mapping. We won't use it in training but it's useful when presenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_code = {0: \"angry\",\n",
    "                1: \"disgust\",\n",
    "                2: \"fear\",\n",
    "                3: \"happy\",\n",
    "                4: \"sad\",\n",
    "                5: \"surprise\",\n",
    "                6: \"neutral\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is already very clean. The images wrap tightly around faces so there isn't much point in any further processing; we can go straight to training. Of course, if we wanted to use the classifier on an image not from this dataset we would have to find a way to use the classifier trained on this dataset for it. This will require detecting faces in that new, foreign image and resizing them to work with our classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
